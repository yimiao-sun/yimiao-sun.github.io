[
    {
        "bibtex": "@inproceedings{yulong2024elase,\ntitle = {ELASE: Enabling Real-time Elastic Sensing Resource Scheduling in 5G vRAN},\nauthor = {Chen, Yulong and Guo, Junchen and Sun, Yimiao and Yao, Haipeng and Liu, Yunhao and He, Yuan},\nbooktitle = {Proceedings of IEEE/ACM IWQoS}, \nyear = {2024}\n}\n",
        "authors": {
            "boldAuthors": ["Yimiao Sun"]
        },
        "note": "IEEE/ACM IWQoS'24",
        "resources": {
            "pdf": "./files/PDF/ElaSe_IWQoS.pdf",   
            "slides": "./files/Slides/ElaSe_PPT.pdf"
        },
        "abstract": "Integrated Sensing and Communication (ISAC) has been witnessed to be a new paradigm of wireless sensing in 5G networks. Users can benefit from pervasive sensing applications in various scenarios with no communication penalty. Given the diverse demands for sensing resources across different sensing tasks, elastic resource scheduling becomes crucial, particularly when resources are constrained. However, existing approaches often treat users equally, limiting their applicability in dealing with diverse sensing tasks in the real world. In this paper, we introduce ElaSe, a pioneering sensing technique that enables real-time elastic scheduling of sensing resources. At the core of ElaSe is the exploration of the user’s state to precisely determine the sensing resource requirements and schedule resources accordingly. We build the first model for matching sensing resources with sensing demands, and further propose a predictive scheduling scheme to eliminate delays by leveraging the 5G virtualized radio access network (vRAN). We conduct experiments to evaluate the performance of ElaSe under different settings. The results demonstrate that ElaSe outperforms the non-scheduling scheme, with a 34% reduction in trajectory tracking error and a 92% decrease in resource allocation error."
    },
    {
        "bibtex": "@inproceedings{yang2024trident,\ntitle = {TRIDENT: Interference Avoidance in Multi-reader Backscatter Network via Frequency-space Division},\nauthor = {Zou, Yang and Na, Xin and Guo, Xiuzhen and Sun, Yimiao and He, Yuan},\nbooktitle = {Proceedings of IEEE INFOCOM}, \nyear = {2024}\n}\n",
        "authors": {
            "boldAuthors": ["Yimiao Sun"]
        },
        "note": "IEEE INFOCOM'24",
        "resources": {
            "pdf": "./files/PDF/TRIDENT_INFOCOM.pdf",
            "slides": "./files/Slides/TRIDENT_PPT.pdf"
        },
        "abstract": "Backscatter is an enabling technology for battery-free sensing in industrial IoT applications. For the purpose of full coverage of numerous tags in the deployment area, one often needs to deploy multiple readers, each of which is to communicate with tags within its communication range. But the actual backscattered signals from a tag are likely to reach a reader outside its communication range, causing undesired interference. Conventional approaches for interference avoidance, either TDMA or CSMA based, separate the readers’ media accesses in the time dimension and suffer from limited network throughput. In this paper, we propose TRIDENT, a novel backscatter tag design that enables interference avoidance with frequency-space division. By incorporating a tunable bandpass filter and multiple terminal loads, a TRIDENT tag is able to detect its channel condition and adaptively adjust the frequency band and the power of its backscattered signals, so that all the readers in the network can operate concurrently without being interfered. We implement TRIDENT and evaluate its performance under various settings. The results demonstrate that TRIDENT enhances the network throughput by 3.18×, compared to the TDMA based scheme."
    },
    {
        "bibtex": "@inproceedings{yimiao2023bifrost,\ntitle = {BIFROST: Reinventing WiFi Signals Based on Dispersion Effect for Accurate Indoor Localization},\nauthor = {Sun, Yimiao and He, Yuan and Zhang, Jiacheng and Na, Xin and Chen, Yande and Wang, Weiguo and Guo, Xiuzhen},\nbooktitle = {Proceedings of ACM SenSys}, \nyear = {2023}\n}\n",
        "authors": {
            "boldAuthors": ["Yimiao Sun"]
        },
        "note": "ACM SenSys'23",
        "resources": {
            "pdf": "./files/PDF/BIFROST_SenSys.pdf",
            "slides": "./files/Slides/BIFROST_PPT.pdf"
        },
        "abstract": "WiFi-based device localization is a key enabling technology for smart applications, which has attracted numerous research studies in the past decade. Most of the existing approaches rely on Line-of-Sight (LoS) signals to work, while a critical problem is often neglected: In the real-world indoor environments, WiFi signals are everywhere, but very few of them are usable for accurate localization. As a result, the localization accuracy in practice is far from being satisfactory. This paper presents BIFROST, a novel hardware-software co-design for accurate indoor localization. The core idea of BIFROST is to reinvent WiFi signals, so as to provide sufficient LoS signals for localization. This is realized by exploiting the dispersion effect of signals emitted by the leaky wave antenna (LWA). We present a low-cost plug-in design of LWA that can generate orthogonal polarized signals: On one hand, LWA disperses signals of different frequencies to different angles, thus providing Angle-of-Arrival (AoA) information for the localized target. On the other hand, the target further leverages the antenna polarization mismatch to distinguish AoAs from different LWAs. In the software layer, fine-grained information in Channel State Information (CSI) is exploited to cope with multipath and noise. We implement BIFROST and evaluate its performance under various settings. The results show that the median localization error of BIFROST is 0.81m, which is 52.35% less than that of SpotFi, a state-of-the-art approach. SpotFi, when combined with BIFROST to work in the realistic settings, can reduce the localization error by 33.54%."
    },
    {
        "bibtex": "@inproceedings{weiguo2023metaspeaker,\ntitle = {Meta-Speaker: Acoustic Source Projection by Exploiting Air Nonlinearity},\nauthor = {Wang, Weiguo and He, Yuan and Jin, Meng and Sun, Yimiao and Guo, Xiuzhen},\nbooktitle = {Proceedings of ACM MobiCom}, \nyear = {2023}\n}\n",
        "authors": {
            "boldAuthors": ["Yimiao Sun"]
        },
        "note": "ACM MobiCom'23",
        "resources": {
            "pdf": "./files/PDF/MetaSpeaker_MobiCom.pdf",
            "slides": "./files/Slides/MetaSpeaker_PPT.pdf"
        },
        "abstract": "This paper proposes Meta-Speaker, an innovative speaker capable of projecting audible sources into the air with a high level of manipulability. Unlike traditional speakers that emit sound waves in all directions, Meta-Speaker can manipulate the granularity of the audible region, down to a single point, and can manipulate the location of the source. Additionally, the source projected by Meta-Speaker is a physical presence in space, allowing both humans and machines to perceive it with spatial awareness. Meta-Speaker achieves this by leveraging the fact that air is a nonlinear medium, which enables the reproduction of audible sources from ultrasounds. Meta-Speaker comprises two distributed ultrasonic arrays, each transmitting a narrow ultrasonic beam. The audible source can be reproduced at the intersection of the beams. We present a comprehensive profiling of Meta-Speaker to validate the high manipulability it offers. We prototype Meta-Speaker and demonstrate its potential through three applications: anchor-free localization with a median error of 0.13 m, location-aware communication with a throughput of 1.28 Kbps, and acoustic augmented reality where users can perceive source direction with a mean error of 9.8 degrees."
    },
    {
        "bibtex": "@inproceedings{jia2023mmhawkeve,\ntitle = {mmHawkeye: Passive UAV Detection with a COTS mmWave Radar},\nauthor = {Zhang, Jia and Na, Xin and Xi, Rui and Sun, Yimiao and He, Yuan},\nbooktitle = {Proceedings of IEEE SECON}, \nyear = {2023}\n}\n",
        "authors": {
            "boldAuthors": ["Yimiao Sun"]
        },
        "note": "IEEE SECON'23",
        "resources": {
            "pdf": "./files/PDF/mmHawkeye_SECON.pdf",
            "slides": "./files/Slides/mmHawkeye_PPT.pdf"
        },
        "abstract": "Small Unmanned Aerial Vehicles (UAVs) are becoming potential threats to security-sensitive areas and personal  privacy.  A UAV can shoot photos at height, but how to detect such  an uninvited intruder is an open problem.  This paper presents  mmHawkeye, a passive approach for UAV detection with a COTS  millimeter wave (mmWave) radar.  mmHawkeye doesn’t require  prior knowledge of the type, motions, and flight trajectory of  the UAV, while exploiting the signal feature induced by the UAV’s periodic micro-motion (PMM) for long-range accurate  detection.  The design is therefore effective in dealing with lowSNR and uncertain reflected signals from the UAV.  mmHawkeye  can further track the UAV’s position with dynamic programming  and particle filtering, and identify it with a Long Short-Term Memory (LSTM) based detector.  We implement mmHawkeye on  a commercial mmWave radar and evaluate its performance under  varied settings.  The experimental results show that mmHawkeye  has a detection accuracy of 95.8% and can realize detection at  a range up to 80m."
    },    
    {
        "bibtex": "@inproceedings{yimiao2023aim,\ntitle = {AIM: Acoustic Inertial Measurement for Indoor Drone Localization and Tracking},\nauthor = {Sun, Yimiao and Wang, Weiguo and Mottola, Luca and Wang, Ruijin and He, Yuan},\nbooktitle = {Proceedings of ACM SenSys},\nyear = {2022}\n}\n",
        "authors": {
            "boldAuthors": ["Yimiao Sun"]
        },
        "note": "ACM SenSys'22",
        "resources": {
            "pdf": "./files/PDF/AIM_SenSys.pdf",
            "slides": "./files/Slides/AIM_PPT.pdf",
            "code": null,
            "demo": null
        },
        "abstract": "We present Acoustic Inertial Measurement (AIM), a one-of-a-kind technique for indoor drone localization and tracking. Indoor drone localization and tracking are arguably a crucial, yet unsolved challenge: in GPS-denied environments, existing approaches enjoy limited applicability, especially in Non-Line of Sight (NLoS), require extensive environment instrumentation, or demand considerable hardware/software changes on drones. In contrast, AIM exploits the acoustic characteristics of the drones to estimate their location and derive their motion, even in NLoS settings. We tame location estimation errors using a dedicated Kalman filter and the Interquartile Range rule (IQR). We implement AIM using an off-the-shelf microphone array and evaluate its performance with a commercial drone under varied settings. Results indicate that the mean localization error of AIM is 46% lower than commercial UWB-based systems in complex indoor scenarios, where state-of-the-art infrared systems would not even work because of NLoS settings. We further demonstrate that AIM can be extended to support indoor spaces with arbitrary ranges and layouts without loss of accuracy by deploying distributed microphone arrays."
    },
    {
        "bibtex": "@inproceedings{weiguo2023micnest,\ntitle = {MicNest: Long-Range Instant Acoustic Localization of Drones in Precise Landing},\nauthor = {Wang, Weiguo and Mottola, Luca and He, Yuan and Li, Jinming and Sun, Yimiao and Li, Shuai and Jing, Hua and Wang, Yulei},\nbooktitle = {Proceedings of ACM SenSys},\nyear = {2022}\n}\n",
        "authors": {
            "boldAuthors": ["Yimiao Sun"]
        },
        "note": "ACM SenSys'22",
        "resources": {
            "pdf": "./files/PDF/MicNest_SenSys.pdf",
            "slides": "./files/Slides/MicNest_PPT.pdf",
            "code": null,
            "home": "https://micnest.github.io/",
            "award": "https://sensys.acm.org/2022/award/"
        },
        "abstract": "We present MicNest: an acoustic localization system enabling precise landing of aerial drones. Drone landing is a crucial step in a drone's operation, especially as high-bandwidth wireless networks, such as 5G, enable beyond-line-of-sight operation in a shared airspace and applications such as instant asset delivery with drones gain traction. In MicNest, multiple microphones are deployed on a landing platform in carefully devised configurations. The drone carries a speaker transmitting purposefully-designed acoustic pulses. The drone may be localized as long as the pulses are correctly detected. Doing so is challenging: i) because of limited transmission power, propagation attenuation, background noise, and propeller interference, the Signal-to-Noise Ratio (SNR) of received pulses is intrinsically low; ii) the pulses experience non-linear Doppler distortion due to the physical drone dynamics while airborne; iii) as location information is to be used during landing, the processing latency must be reduced to effectively feed the flight control loop. To tackle these issues, we design a novel pulse detector, Matched Filter Tree (MFT), whose idea is to convert pulse detection to a tree search problem. We further present three practical methods to accelerate tree search jointly. Our real-world experiments show that MicNest is able to localize a drone 120 m away with 0.53% relative localization error at 20 Hz location update frequency."
    }

]