[
    {
        "bibtex": "@article{liu2024real,\ntitle = {Real-Time Continuous Activity Recognition With a Commercial mmWave Radar},\nauthor = {Liu, Yunhao and Zhang, Jia and Chen, Yande and Wang, Weiguo and Yang, Songzhou and Na, Xin and Sun, Yimiao and He, Yuan},\njournal = {IEEE Transactions on Mobile Computing},\nyear = {2024}\n}\n",
        "authors": {
            "boldAuthors": ["Yimiao Sun"]
        },
        "note": "IEEE TMC'24",
        "resources": {
        },
        "abstract": "mmWave-based activity recognition technology has attracted widespread attention as it provides the ability of device-free, ubiquitous and accurate sensing. Recognition of human activities intrinsically demands to be real-time and continuous, but the state of the arts is still far limited with the capacity in this regard. The main obstacle lies in activity sequence segmentation, i.e., locating the boundaries between consecutive activities in an activity sequence. This is a daunting task, due to the unclear activity boundaries and the variable activity duration. In this paper, we propose ZuMa , the first mmWave-based approach to real-time continuous activity recognition. When resorting to a machine learning model for activity recognition, our insight is that the recognition confidence of the recognition model is highly correlated to the accuracy of activity sequence segmentation, so that the former can be utilized as a feedback metric to finely adjust the segmentation boundaries. Based on this insight, ZuMa is a coarse-to-fine grained approach, which includes the fast coarse-grained activity chunk extraction and the find-grained explicit segmentation adjustment and recognition. We have implemented ZuMa with the commercial mmWave radar and evaluated its performance under various settings. The results demonstrate that ZuMa achieves an average recognition error of 12.67%, which is 65.08% and 71.87% lower than that of the two baseline methods. The average recognition delay of ZuMa is only 1.86s."
    },
    {
        "bibtex": "@article{zou2024trident,\ntitle = {Trident: Interference Avoidance in Multi-Reader Backscatter Network via Frequency-Space Division},\nauthor = {Zou, Yang and Na, Xin and Sun, Yimiao and He, Yuan},\njournal = {IEEE/ACM Transactions on Networking},\nyear = {2024}\n}\n",
        "authors": {
            "boldAuthors": ["Yimiao Sun"]
        },
        "note": "IEEE/ACM ToN'24",
        "resources": {
        },
        "abstract": "Backscatter is a key technology for battery-free sensing in industrial IoT applications. To fully cover numerous tags in the deployment area, one often needs to deploy multiple readers, each of which communicates with tags within its communication range. However, the actual backscattered signals from a tag are likely to reach a reader outside its communication range and cause interference. Conventional TDMA or CSMA based approaches for interference avoidance separate readers’ media access in time, leading to limited network throughput. In this paper, we propose Trident, a novel backscatter design that enables interference avoidance via frequency-space division. By incorporating a tunable bandpass filter and multiple terminal loads, a Tridenttag can detect its channel condition and adaptively adjust the frequency and the power of its backscattered signals. We further propose a frequency assignment algorithm for the readers. With these designs, all the readers in the network can operate concurrently without being interfered. We implement Tridentand evaluate its performance under various settings. The results demonstrate that Tridentenhances the network throughput by 3.18 × , compared to the TDMA-based scheme."
    },
    {
        "bibtex": "@article{yuan2023detection,\ntitle = {Detection and Identification of Non-Cooperative UAV Using a COTS mmWave Radar},\nauthor = {He, Yuan and Zhang, Jia and Xi, Rui and Na, Xin and Sun, Yimiao and Li, Beibei},\njournal = {ACM Transactions on Sensor Networks},\nyear = {2023},\nvolume = {20},\nnumber = {2},\npages = {1-22}\n}\n",
        "authors": {
            "boldAuthors": ["Yimiao Sun"]
        },
        "note": "ACM TOSN'23",
        "resources": {
        },
        "abstract": "Small Unmanned Aerial Vehicles (UAVs) are becoming potential threats to security-sensitive areas and personal privacy. A UAV can shoot photos at height, but how to detect such an uninvited intruder is an open problem. This paper presents mmHawkeye, a passive approach for non-cooperative UAV detection and identification with a COTS millimeter wave (mmWave) radar. mmHawkeye doesn’t require prior knowledge of the type, motions, and flight trajectory of the UAV, while exploiting the signal feature induced by the UAV’s periodic micro-motion (PMM) for long-range accurate detection. The design is therefore effective in dealing with low-SNR and uncertain reflected signals from the UAV. After analyzing the theoretical model of the PMM feature, mmHawkeye can further track the UAV’s position containing range, azimuth and altitude angle with dynamic programming and particle filtering, and then identify it with a Long Short-Term Memory (LSTM) based detector. We implement mmHawkeye on a commercial mmWave radar and evaluate its performance under varied settings. The experimental results show that mmHawkeye has a detection accuracy of 95.8% and can realize detection at a range up to 80m."
    }, 
    {
        "bibtex": "@article{yimiao2023indoor,\ntitle = {Indoor Drone Localization and Tracking Based on Acoustic Inertial Measurement},\nauthor = {Sun, Yimiao and Wang, Weiguo and Mottola, Luca and Jia, Zhang and Wang, Ruijin and He, Yuan},\njournal = {IEEE Transactions on Mobile Computing},\nyear = {2024},\nvolume = {23},\nnumber = {6},\npages = {7537-7551}\n}\n",
        "authors": {
            "boldAuthors": ["Yimiao Sun"]
        },
        "note": "IEEE TMC'23",
        "resources": {
        },
        "abstract": "We present Acoustic Inertial Measurement (AIM), a one-of-a-kind technique for indoor drone localization and tracking. Indoor drone localization and tracking are arguably a crucial, yet unsolved challenge: in GPS-denied environments, existing approaches enjoy limited applicability, especially in Non-Line of Sight (NLoS), require extensive environment instrumentation, or demand considerable hardware/software changes on drones. In contrast, AIM exploits the acoustic characteristics of the drones to estimate their location and derive their motion, even in NLoS settings. We tame location estimation errors using a dedicated Kalman filter and the Interquartile Range rule (IQR) and demonstrate that AIM can support indoor spaces with arbitrary ranges and layouts. We implement AIM using an off-the-shelf microphone array and evaluate its performance with a commercial drone under varied settings. Results indicate that the mean localization error of AIM is 46% lower than that of commercial UWB-based systems in a complex 10m×10m indoor scenario, where state-of-the-art infrared systems would not even work because of NLoS situations. When distributed microphone arrays are deployed, the mean error can be reduced to less than 0.5m in a 20m range, and even support spaces with arbitrary ranges and layouts."
    },
    
    {
        "bibtex": "@article{weiguo2023acoustic,\ntitle = {Acoustic Localization of Drones in Precise Landing: The Research and Practice with MicNest},\nauthor = {Wang, Weiguo and He, Yuan and Mottola, Luca and Li, Shuai and Sun, Yimiao and Li, Jinming and Jing, Hua and Wang, Ting and Wang, Yulei},\njournal = {GetMobile: Mobile Computing and Communications},\nyear = {2023},\nvolume = {27},\nnumber = {3},\npages = {27–32}\n}\n",
        "authors": {
            "boldAuthors": ["Yimiao Sun"]
        },
        "note": "ACM GetMobile'23",
        "resources": {
        },
        "abstract": "Delivery drones have the potential to revolutionize transportation and distribution of goods. With their autonomous navigation capabilities, they offer an efficient solution to bypass the challenges posed by complex urban traffic and enable instant package delivery. Many industrial firms are actively exploring the commercial feasibility of instant drone deliveries. Meituan, one of the largest companies in this area, devised a systematic approach to instant delivery using drones. The process begins with loading the package onto the drone, which then takes off, ascends to cruising altitude, and sets a direct course towards the designated destination. Typically, this destination is a Meituan-operated self-collection station located near the customer."
    },

    {
        "bibtex": "@ARTICLE{yuan2023acoustic,\ntitle = {Acoustic Localization System for Precise Drone Landing},\nauthor = {He, Yuan and Wang, Weiguo and Mottola, Luca and Li, Shuai and Sun, Yimiao and Li, Jinming and Jing, Hua and Wang, Ting and Wang, Yulei},\njournal = {IEEE Transactions on Mobile Computing},\nyear = {2024},\nvolume = {23},\nnumber = {5},\npages = {4126-4144}\n}\n",
        "authors": {
            "boldAuthors": ["Yimiao Sun"]
        },
        "note": "IEEE TMC'23",
        "resources": {
        },
        "abstract": "We present MicNest : an acoustic localization system enabling precise drone landing. In MicNest , multiple microphones are deployed on a landing platform in carefully devised configurations. The drone carries a speaker transmitting purposefully-designed acoustic pulses. The drone may be localized as long as the pulses are correctly detected. Doing so is challenging: i) because of limited transmission power, propagation attenuation, background noise, and propeller interference, the Signal-to-Noise Ratio (SNR) of received pulses is intrinsically low; ii) the pulses experience non-linear Doppler distortion due to the physical drone dynamics; iii) as location information is used during landing, the processing latency must be reduced to effectively feed the flight control loop. To tackle these issues, we design a novel pulse detector, Matched Filter Tree (MFT), whose idea is to convert pulse detection to a tree search problem. We further present three practical methods to accelerate tree search jointly. Our experiments show that MicNest can localize a drone 120 m away with 0.53% relative localization error at 20 Hz location update frequency. For navigating drone landing, MicNest can achieve a success rate of 94 %. The average landing error (distance between landing point and target point) is only 4.3 cm."
    },

    {
        "bibtex": "@ARTICLE{jia2023survey,\ntitle = {A Survey of mmWave-Based Human Sensing: Technology, Platforms and Applications},\nauthor = {Zhang, Jia and Xi, Rui and He, Yuan and Sun, Yimiao and Guo, Xiuzhen and Wang, Weiguo and Na, Xin and Liu, Yunhao and Shi, Zhenguo and Gu, Tao},\njournal = {IEEE Communications Surveys & Tutorials},\nyear = {2023},\nvolume = {25},\nnumber = {4},\npages = {2052-2087}\n}\n",
        "authors": {
            "boldAuthors": ["Yimiao Sun"]
        },
        "note": "IEEE COMST'23",
        "resources": {
        },
        "abstract": "With the rapid development of the Internet of Things (IoT) and the rise of 5G communication networks and automatic driving, millimeter wave (mmWave) sensing is emerging and starts impacting our life and workspace. mmWave sensing can sense humans and objects in a contactless way, providing fine-grained sensing ability. In the past few years, many mmWave sensing techniques have been proposed and applied in various human sensing applications (e.g., human localization, gesture recognition, and vital monitoring). We discover the need of a comprehensive survey to summarize the technology, platforms and applications of mmWave-based human sensing. In this survey, we first present the mmWave hardware platforms and some key techniques of mmWave sensing. We then provide a comprehensive review of existing mmWave-based human sensing works. Specifically, we divide existing works into four categories according to the sensing granularity: human tracking and localization, motion recognition, biometric measurement and human imaging. Finally, we discuss the potential research challenges and present future directions in this area."
    }
]